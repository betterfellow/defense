# Defense against Adversarial Attacks
~~Defense against the Dark Arts~~

![Harry](https://github.com/betterfellow/defense/blob/master/hogwarts.jpg?raw=true)

본 프로젝트는 2017년 2학기 연세대학교 소프트웨어 종합설계를 위한 Defense against Adversarial Attacks 프로젝트입니다.

  

## Contributor
이상헌, 김현우, 박세환

  

## Reference

* VAEs
  * D.P. Kingma, [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114), 2014 : VAE
  * X. Yan, [Attribute2image: Conditional Image Generation from Visual Attributes](http://link.springer.com/chapter/10.1007/978-3-319-46493-0_47), 2016 : Conditional VAE
  * P. Vincent, [Extracting and Composing Robust Features with Denoising Autoencoders](http://dl.acm.org/citation.cfm?id=1390294), 2008: dAE
  * D.J. Im, [Denoising Criterion for Variational Auto-Encoding Framework](http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14213/14374), 2017: denoising VAE
* Attacks & Defenses
  * C. Szegedy, [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199), 2013
  * I.J. Goodfellow, [Explaining and harnessing adversarial examples](https://arxiv.org/abs/1412.6572), 2014
  * N. Papernot, [Practical black-box attacks against deep learning systems using adversarial examples](https://arxiv.org/abs/1602.02697), 2016
  * S.M. Moosavi-Dezfooli, [Universal adversarial perturbations](https://arxiv.org/abs/1610.08401), 2017
  * S.M. Moosavi-Dezfooli, [Analysis of universal adversarial perturbations](https://arxiv.org/abs/1705.09554), 2017
  * Y. Song, [PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples](https://arxiv.org/abs/1710.10766), 2017